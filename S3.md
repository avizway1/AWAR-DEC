### **S3: Simple Storage Service**

---

#### **Object-Based Storage**
- **Definition:** Designed for storing flat files like documents, images, videos, and backups. Applications and operating systems cannot be installed or run on S3.  
  **Examples:** Dropbox, Google Drive.

---

#### **Other Storage Types**
1. **Block-Based Storage:**
   - Designed for running operating systems and applications.
   - Examples: EBS, Instance Store Volumes (used with EC2 instances).
2. **File-Based Storage:**
   - Network-based storage mounted to multiple devices.
   - Examples: EFS, FSx (used with EC2 instances).

---

#### **Key Features of S3**
- **Object Storage:** Ideal for storing flat files like logs, images, and videos.
- **Data Organization:** Data is stored in **buckets**.
- **Global Uniqueness:** Bucket names must be unique across all AWS accounts globally.
- **Soft Limit:** By default, an account can create up to 10000 buckets.
- **Scalability:** Unlimited data can be stored within a bucket.
- **No Pre-Provisioning:** Automatically scales as data is added.
  
---

#### **Bucket Naming Rules**
1. **Length:** Minimum 3 characters, maximum 63 characters.
2. **Character Restrictions:**
   - Must use lowercase letters and numbers.
   - Cannot start or end with a period (`.`).
   - Adjacent periods (`..`) are not allowed.
   - Must not resemble an IP address (e.g., `192.168.100.1`).

---

#### **Free Tier Eligibility**
- **5 GB** Standard Storage.
- **2,000 PUT** (uploads) / **20,000 GET** (downloads).

---

#### **Object Storage Details**
- **Object Size:** Minimum size: **0 bytes**, Maximum size: **5 TB**.
- **Region-Specific:** While S3 is a global service, the data resides in the AWS Region's Availability Zones (AZs) where the bucket is created.

#### **Example URLs:**
1. **Path-Style URL (Legacy):** `https://s3.ap-south-1.amazonaws.com/bucketname/objectname`
2. **Virtual-Hosted URL:** 
   - `https://bucketname.s3.ap-south-1.amazonaws.com/objectname`
   - `https://bucketname.s3.amazonaws.com/objectname`
3. **Note:** Virtual paths won't work for bucket names containing periods (`.`).

---

#### **Making an Object Public**
1. **Account-Level Blocking:**
   - Ensure "Block Public Access" is disabled at the account level.
2. **Bucket-Level Blocking:**
   - Disable "Block Public Access" for the specific bucket.
3. **Object-Level Setting:**
   - Use ACLs to make the object public:
     - Navigate to the object → Actions → Make public using ACL.

---

### **We have total 3 types of buckets.**
- general Purpose bucket
- Directory Bucket
- Table bucket
---

### **1. General Purpose Buckets**
- **Description:**  
  General Purpose Buckets are the original S3 bucket type, suitable for most use cases and access patterns. They support a wide range of storage classes, except for specific single-zone storage classes like **S3 Express One Zone** and **S3 One Zone-IA** in AWS Local Zones.

- **Primary Use Cases:**  
  - Storing frequently or infrequently accessed data across multiple Availability Zones (AZs).  
  - General-purpose storage for web applications, media hosting, or data backups.  
  - Use cases requiring high durability and availability across multiple AZs.

- **Supported Storage Classes:**  
  - **S3 Standard**  
  - **S3 Standard-IA**  
  - **S3 Glacier Flexible Retrieval**  
  - **S3 Glacier Deep Archive**  

---

### **2. Directory Buckets**
- **Description:**  
  Directory Buckets are designed for specific use cases requiring low-latency or data residency, allowing bucket creation in a specific location such as an Availability Zone or a Local Zone.  
  - **Availability Zone (AZ):** Supports the **S3 Express One Zone** storage class for low-latency, high-performance workloads.  
  - **Local Zone:** Supports the **S3 One Zone-IA (Z-IA)** storage class for data residency requirements.

- **Primary Use Cases:**  
  - **High-Performance Workloads:**  
    - For latency-sensitive applications requiring single-digit millisecond PUT and GET operations in an AZ.  
    - Example: Analytics or real-time processing.  
  - **Data Residency Workloads:**  
    - Storing data in a specific AWS Local Zone to meet residency or compliance requirements.  

- **Supported Storage Classes:**  
  - **S3 Express One Zone** (for Availability Zone workloads).  
  - **S3 One Zone-IA** (for Local Zone workloads).  

---

### **3. Table Buckets**
- **Description:**  
  Table Buckets are used to store structured or tabular data, often serialized in formats like JSON, CSV, Parquet, or Avro. These buckets are optimized for use in data lakes and analytics workflows.

- **Primary Use Cases:**  
  - **Data Analytics:**  
    - Storing structured data for querying using tools like Amazon Athena, AWS Glue, or Redshift Spectrum.  
  - **Data Lakes:**  
    - Serving as a central repository for data that can be processed and analyzed.  
  - **Database Export/Import:**  
    - Exporting and importing tabular data to and from relational or NoSQL databases.  

- **Common File Formats:**  
  - JSON, CSV, Parquet, Avro.  

---

### **Comparison Table**

| **Feature**                        | **General Purpose Buckets**                  | **Directory Buckets**                             | **Table Buckets**                                |
|------------------------------------|---------------------------------------------|--------------------------------------------------|-------------------------------------------------|
| **Scope**                          | Multi-AZ                                     | Single AZ or Local Zone                          | Multi-AZ (typically).                           |
| **Latency**                        | Standard                                     | Low latency (single-digit millisecond).          | Optimized for query workloads (varies by tools).|
| **Use Case**                       | General-purpose storage for diverse data.    | Performance-sensitive or residency workloads.    | Data lakes, analytics, and structured storage.  |
| **Supported Storage Classes**      | S3 Standard, Standard-IA, Glacier classes.   | S3 Express One Zone, S3 One Zone-IA.            | S3 Standard, Intelligent Tiering, Glacier.      |

---

<img width="1220" alt="Screenshot 2024-12-27 at 9 03 08 AM" src="https://github.com/user-attachments/assets/da56e22b-79ba-4b15-a58a-ef2cc379c054" />



### **S3 Commonly used Storage Classes Use Cases**
1. **S3 Standard (Default):**  
   - **Use Case:** Frequently accessed data.  
   - **Availability:** 99.99%, **Durability:** 99.999999999% (11 nines).  
   - **Replication:** Data stored across **≥3 AZs**.

2. **S3 Standard-IA (Infrequent Access):**  
   - **Use Case:** Infrequently accessed data.  
   - **Availability:** 99.9%, **Durability:** 99.999999999%.  
   - **Replication:** Data stored across **≥3 AZs**.

3. **S3 One Zone-IA:**  
   - **Use Case:** Infrequently accessed non-critical data.  
   - **Availability:** 99.5%, **Durability:** 99.999999999%.  
   - **Replication:** Data stored in **1 AZ**.

4. **S3 Glacier Flexible Retrieval:**  
   - **Use Case:** Long-term archival storage (retrieval in minutes to hours).  
   - **Availability:** 99.99%, **Durability:** 99.999999999%.  
   - **Replication:** Data stored across **≥3 AZs**.  

5. **S3 Glacier Deep Archive:**  
   - **Use Case:** Long-term archival with 12+ hour retrieval times.  
   - **Replication:** Data stored across **≥3 AZs**.

6. **S3 Intelligent-Tiering:**  
   - **Use Case:** Optimized cost for unknown access patterns.  
   - **Availability:** 99.9%, **Durability:** 99.999999999%.  
   - **Replication:** Data stored across **≥3 AZs**.

---

#### **Data Retrieval Types (Glacier)**
- **Bulk:** 5–12 hours.  
- **Standard:** 3–5 hours.  
- **Expedited:** 1–5 minutes (up to 250 MB).

---

#### **Task : Create an S3 bucket. Upload and object, make it public. Verify object access using Object URL.**
**Try to understand aws s3 storage classes. (Certification exam topic)
---

#### **S3 Pricing Factors**
1. Data stored in buckets.  
2. Number of PUT (upload) and GET (download) requests.  
3. Data retrieval and transfer costs.


## **S3 Versioning**

### **Overview**
- S3 Versioning allows you to maintain multiple versions of an object within the same bucket.
- By default, versioning is in a **Suspended** state for any bucket.
- Once versioning is **enabled**, S3 will keep track of all versions of objects in the bucket.

### **Delete Behavior**
1. **Typing "Delete" when deleting an object:**  
   - S3 creates a **Delete Marker**, making the object invisible in the current version view.
   - You can delete the Delete Marker to recover the object.

2. **Typing "Permanently Delete" when deleting an object:**  
   - The object is permanently removed, and no Delete Marker is created.

### **Key Scenarios**
1. **Versioning Enabled:**
   - **HIDE Mode (Default View):**
     - Only the most recent version (current version) is visible.
     - Deleting an object adds a Delete Marker.
     - To recover the object, switch to "SHOW Versions," locate the Delete Marker, and remove it.
   - **SHOW Mode (Version View):**
     - All versions, including older ones and Delete Markers, are visible.
     - Deleting an object in this mode removes it permanently.

2. **Versioning Suspended:**
   - No version tracking occurs.
   - Deleting an object will permanently remove it.

---

## **Lifecycle Management Rules**

Lifecycle Management Rules help automate object transitions and deletions to optimize storage costs.

### **Scope of Rules**
- **Entire Bucket:** Apply rules to all objects in the bucket.
- **Prefix-Based Rules:** Apply rules to specific folders or object paths within the bucket.
- **Tag-Based Rules:** Apply rules only to objects with specific tags.

### **Sample Scenarios**
1. **S3 Standard → Standard-IA → Glacier → Delete**  
   Objects transition through Standard-IA (Infrequent Access) to Glacier and are eventually deleted.

2. **S3 Standard → Glacier → Delete**  
   Objects transition directly to Glacier and are deleted after a retention period.

3. **S3 Standard → Delete**  
   Objects remain in Standard storage before being deleted without transitioning to lower-cost tiers.


![lifecycle-transitions-v3](https://github.com/user-attachments/assets/4c597e4f-a1b3-49c7-970b-e558e92af2d1)


---

## **Replication Rules**

### **Cross-Region Replication (CRR) / Same-Region Replication (SRR)**
Replication ensures objects are copied from a source bucket to a destination bucket.

- **Requirements:**
  - Both source and destination buckets must have versioning enabled.
  - Existing objects are **not replicated**; only future uploads are replicated.
  - To replicate all existing objects, AWS offers **AWS Batch** job to replicate. **Cost US**

- **Replication Time Control (RTC):**
  - Guarantees data replication to the destination bucket within **15 minutes** for 99.99% of the data.
  - Additional costs apply for RTC.

### **Cost Considerations**
- **Data Transfer Between Regions:** Charges apply for data transfer.
- **Data Transfer Within a Region:** No cost for replication within the same region.

### **Manual Replication Using AWS CLI**
For one-time or scheduled replication, use the AWS CLI `sync` command:

```bash
aws s3 sync s3://source-bucket s3://target-bucket
```
- Schedule the command using:
  - **Windows Task Scheduler**
  - **Linux Cron Jobs** (e.g., daily replication at 12:00 AM).

---

## **Summary Table**

| **Feature**                        | **Behavior**                                                                                     |
|------------------------------------|--------------------------------------------------------------------------------------------------|
| **Versioning Default State**       | Suspended                                                                                       |
| **Delete Behavior (Versioning ON)**| Creates a Delete Marker; delete the marker to recover the object.                               |
| **Delete Behavior (Versioning OFF)**| Permanently deletes the object.                                                                |
| **Lifecycle Rules Scope**          | Entire bucket, prefix-based, or tag-based rules.                                                |
| **Replication Requirements**       | Source and destination buckets must have versioning enabled.                                    |
| **Replication Time Control**       | Guarantees replication within 15 minutes for 99.99% of data (additional cost).                  |
| **Manual Replication**             | Use AWS CLI `sync` command for scheduled or ad-hoc replication.                                 |

---


## **Event Notifications**

### **When to Use S3 Event Notifications**  
S3 event notifications are helpful when you want to automate tasks or trigger actions in response to certain changes in your S3 bucket. Some common use cases include:  
- **Data Ingestion:** Notify downstream systems whenever a new file is uploaded to the bucket.  
- **Data Processing:** Trigger a Lambda function for image processing, transcoding videos, or extracting metadata from uploaded files.  
- **Monitoring and Alerting:** Use SNS to send alerts for object changes.  
- **Workflow Automation:** Integrate with SQS for queue-based workflows where other systems consume messages.

### **Available Destinations for Event Notifications**  
1. **SNS (Simple Notification Service):**  
   - Enables notifications to subscribers via email, SMS, or HTTP.  
   - **Free Tier:** 1,000 emails per month.  

2. **SQS (Simple Queue Service):**  
   - Reliable and scalable message queuing service.  
   - Suitable for decoupled systems where multiple consumers process events asynchronously.  

3. **Lambda:**  
   - Executes code in response to events.  
   - Ideal for on-the-fly transformations or actions without managing infrastructure.

### **Steps to Configure S3 Event Notifications**  
1. **Create or Identify the Destination:**  
   - For SNS: Create an SNS topic and add subscribers.  
   - For SQS: Set up a queue.  
   - For Lambda: Create the Lambda function.

2. **Modify Permissions:**  
   - **SNS-S3 Integration:**  
     - Update the SNS topic's **Access Policy** to allow S3 to publish messages.  
     - Example policy to allow everyone:  
       ```json
       {
         "Effect": "Allow",
         "Principal": "*",
         "Action": "SNS:Publish",
         "Resource": "arn:aws:sns:<region>:<account-id>:<topic-name>"
       }
       ```
   - Ensure your bucket policy allows events to be sent to the specified destination.

3. **Set Up the Notification on the S3 Bucket:**  
   - Go to the **Properties** tab of the bucket.  
   - Configure event notifications for specific events like **PUT**, **POST**, **DELETE**, or **Restore Object**.

4. **Test the Setup:**  
   - Perform an action on the bucket (e.g., upload a file).  
   - Verify that the event triggers the destination (e.g., email alert, queue message, or Lambda execution).

---

## **Using KMS with S3 for Encryption**

### **What is Encryption?**  
Encryption is the process of converting data into a secure format to prevent unauthorized access. Only authorized users with the correct decryption key can access the original data.

### **Importance of S3 Data Encryption**
- **Data Protection:** Ensures sensitive data is secure both during transmission and at rest.  
- **Regulatory Compliance:** Helps meet compliance requirements like GDPR, HIPAA, or CCPA.  
- **Access Control:** Provides additional layers of security to control who can access or decrypt data.

---

### **Types of Encryption in S3**

#### **1. In-Transit Encryption:**  
- Protects data while being transmitted to or from S3.  
- **Technology Used:**  
  - **SSL (Secure Socket Layer)**  
  - **TLS (Transport Layer Security)**  

#### **2. Server-Side Encryption (SSE) (At Rest):**  
- Protects data stored on the S3 platform.  
- **Options:**  

1. **SSE-S3:**  
   - S3 manages encryption keys (AES-256).  
   - Suitable for public data.  
   - No direct access to key material by users.

2. **SSE-KMS (Key Management Service):**  
   - **AWS Managed Keys (aws/s3):**  
     - Default encryption keys created and managed by AWS KMS.  
     - Cannot be deleted.  
   - **Customer Managed Keys (CMK):**  
     - User-created keys.  
     - Requires permissions for both the S3 bucket and the encryption key.  
     - **Note:** Data encrypted with KMS keys cannot be made public.  

3. **SSE-C (Customer Provided Keys):**  
   - Customer provides key material to AWS.  
   - AWS uses it to encrypt and decrypt data.  
   - Customers can rotate or revoke keys anytime.  

#### **3. Client-Side Encryption (CSE):**  
- Encrypt data using your own tools before uploading it to S3.  
- AWS is not responsible for managing or decrypting the data.

---

### **Steps to Create a KMS Key for S3 Encryption**
1. **Choose Key Type:**  
   - Symmetric (S3 supports only symmetric keys).  
2. **Set Key Administrators:**  
   - Define who can manage the key.  
3. **Assign Key Users:**  
   - Grant access to users or services that will encrypt/decrypt data.  
4. **Review and Create the Key:**  
   - Confirm the configuration and create the key.

---

## **S3 Static Website Hosting**

### **Setup for Static Website Hosting**
1. **Bucket Configuration:**  
   - Create an S3 bucket with the same name as your domain (e.g., `learnaws.co.in`).  
   - Upload your static website files (HTML, CSS, JS).  

2. **Permissions:**  
   - Update the bucket policy to allow public read access.  

3. **Enable Static Website Hosting:**  
   - Go to the bucket’s **Properties** tab.  
   - Enable **Static Website Hosting** and set the index and error document (e.g., `index.html`, `error.html`).

4. **Access Your Website:**  
   - Use the static website endpoint, e.g.,  
     `http://learnaws.co.in.s3-website.ap-south-1.amazonaws.com`

### **Common HTTP Status Codes**
- **2XX:** Success (e.g., 200 OK).  
- **3XX:** Redirection (e.g., 301 Moved Permanently).  
- **4XX:** Client Errors (e.g., 403 Forbidden, 404 Not Found).  
- **5XX:** Server Errors (e.g., 500 Internal Server Error).

---


